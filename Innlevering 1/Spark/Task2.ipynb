{"cells":[{"cell_type":"markdown","source":["#### Names of people in the group\n\nPlease write the names of the people in your group in the next cell."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"83045409-70a5-4010-b1cf-9db8d98f2bad","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Name of person Oda Colquhoun\n\nName of person Emil Bj√∏rlykke Berglund"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"059a269d-8f13-494e-84e5-9da5d873047b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# We need to install 'ipython_unittest' to run unittests in a Jupyter notebook\n!pip install -q ipython_unittest"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"52939e3d-35c7-4767-a59e-ba75f716e952","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Loading modules that we need\nimport unittest\nfrom pyspark.sql.dataframe import DataFrame\nfrom typing import Any"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"499e46f5-12a4-46de-a212-90f2e936461e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# A helper function to load a table (stored in Parquet format) from DBFS as a Spark DataFrame \ndef load_df(table_name: \"name of the table to load\") -> DataFrame:\n    return spark.read.parquet(table_name)\nusers_df = load_df(\"/user/hive/warehouse/users\")\ncomments_df = load_df(\"/user/hive/warehouse/comments\")\nposts_df = load_df(\"/user/hive/warehouse/posts\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7f8c68e0-6bda-40a6-8588-381e51dc0a93","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"users_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Id","nullable":true,"type":"integer"},{"metadata":{},"name":"Reputation","nullable":true,"type":"integer"},{"metadata":{},"name":"CreationDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"DisplayName","nullable":true,"type":"string"},{"metadata":{},"name":"LastAccessDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"AboutMe","nullable":true,"type":"string"},{"metadata":{},"name":"Views","nullable":true,"type":"integer"},{"metadata":{},"name":"UpVotes","nullable":true,"type":"integer"},{"metadata":{},"name":"DownVotes","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null},{"name":"comments_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"PostId","nullable":true,"type":"integer"},{"metadata":{},"name":"Score","nullable":true,"type":"integer"},{"metadata":{},"name":"Text","nullable":true,"type":"string"},{"metadata":{},"name":"CreationDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"UserId","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null},{"name":"posts_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Id","nullable":true,"type":"integer"},{"metadata":{},"name":"ParentId","nullable":true,"type":"integer"},{"metadata":{},"name":"PostTypeId","nullable":true,"type":"integer"},{"metadata":{},"name":"CreationDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Score","nullable":true,"type":"integer"},{"metadata":{},"name":"ViewCount","nullable":true,"type":"integer"},{"metadata":{},"name":"Body","nullable":true,"type":"string"},{"metadata":{},"name":"OwnerUserId","nullable":true,"type":"integer"},{"metadata":{},"name":"LastActivityDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Title","nullable":true,"type":"string"},{"metadata":{},"name":"Tags","nullable":true,"type":"string"},{"metadata":{},"name":"AnswerCount","nullable":true,"type":"integer"},{"metadata":{},"name":"CommentCount","nullable":true,"type":"integer"},{"metadata":{},"name":"FavoriteCount","nullable":true,"type":"integer"},{"metadata":{},"name":"ClosedDate","nullable":true,"type":"timestamp"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Subtask 1: implementing two helper functions\nImpelment these two functions:\n1. 'run_query' that gets a Spark SQL query and run it on df which is a Spark DataFrame; it returns the content of the first column of the first row of the DataFrame that is the output of the query;\n2. 'run_query2' that is similar to 'run_query' but instead of one DataFrame gets two; it returns the content of the first column of the first row of the DataFrame that is the output of the query.\n\nNote that the result of a Spark SQL query is itself a Spark DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a2274f0-1bd8-4812-83d2-f793587e9548","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def run_query(query: \"a SQL query string\", df: \"the DataFrame that the query will be executed on\") -> Any:\n    df.createOrReplaceTempView(\"df\")\n    result = spark.sql(query).collect()[0][0]\n    return result\n    \ndef run_query2(query: \"a SQL query string\", df1: \"DataFrame A\", df2: \"DataFrame B\") -> Any:\n    df1.createOrReplaceTempView(\"df1\")\n    df2.createOrReplaceTempView(\"df2\")\n    result = spark.sql(query).collect()\n    return result[0][0]\n    \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5fce811-7dd2-4602-a243-18a36754c302","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Loading 'ipython_unittest' so we can use '%%unittest_main' magic command\n%load_ext ipython_unittest"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2a021cce-880b-42b1-a09d-6d2c2222124e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Subtask 2: writing a few queries\nWrite the following queries in SQL to be executed by Spark in the next cell.\n\n1. 'q1': find the 'Id' of the most recently created post ('df' is 'posts_df') \n2. 'q2': find the number users\n3. 'q3': find the 'Id' of the user who posted most number of answers\n4. 'q4': find the number of questions\n5. 'q5': find the display name of the user who posted most number of comments\n\nNote that 'q1' is already available below as an example. Moreover, remmebr that Spark supports ANSI SQL 2003 so your queries have to comply with that standard."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7de10aba-7e77-4baa-af35-2b4e37916071","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["q1 = \"SELECT * FROM df ORDER BY CreationDate DESC limit 1\"\n\n\nq2 = \"SELECT COUNT(*) FROM df\"\n\n\n# find the user id of the user who posted most number of answers\nq3 = \"SELECT OwnerUserId FROM df GROUP BY OwnerUserId ORDER BY COUNT(*) DESC limit 1\"\n\n\n\n# find the number of questions\nq4 = \"SELECT COUNT(Id) FROM df WHERE PostTypeId='1'\"\n\n\n# find the display name of the user who posted most number of comments\nq5 = \"SELECT first(DisplayName), COUNT(*) AS count FROM df1 INNER JOIN df2 ON df1.Id=df2.UserId GROUP BY df1.Id ORDER BY count desc LIMIT 1\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c3273ef7-7f4d-4b5d-bcf7-9935c952e26d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Subtask 3: validating the implementations by running the tests\n\nRun the cell below and make sure that all the tests run successfully."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"46400bac-c11c-4bee-81a8-67d42e3ca968","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%%unittest_main\nclass TestTask2(unittest.TestCase):\n    def test_q1(self):\n        # find the id of the most recent post\n        r = run_query(q1, posts_df)\n        self.assertEqual(r, 95045)\n\n    def test_q2(self):\n        # find the number of the users\n        r = run_query(q2, users_df)\n        self.assertEqual(r, 91616)\n\n    def test_q3(self):\n        # find the user id of the user who posted most number of answers\n        r = run_query(q3, posts_df)\n        self.assertEqual(r, 64377)\n\n    def test_q4(self):\n        # find the number of questions\n        r = run_query(q4, posts_df)\n        self.assertEqual(r, 28950)\n        \n\n    def test_q5(self):\n        # find the display name of the user who posted most number of comments\n        r = run_query2(q5, users_df, comments_df)\n        self.assertEqual(r, \"Neil Slater\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"31ca3fb9-427c-425d-b334-0df9c208a21b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"users_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Id","nullable":true,"type":"integer"},{"metadata":{},"name":"Reputation","nullable":true,"type":"integer"},{"metadata":{},"name":"CreationDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"DisplayName","nullable":true,"type":"string"},{"metadata":{},"name":"LastAccessDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"AboutMe","nullable":true,"type":"string"},{"metadata":{},"name":"Views","nullable":true,"type":"integer"},{"metadata":{},"name":"UpVotes","nullable":true,"type":"integer"},{"metadata":{},"name":"DownVotes","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null},{"name":"comments_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"PostId","nullable":true,"type":"integer"},{"metadata":{},"name":"Score","nullable":true,"type":"integer"},{"metadata":{},"name":"Text","nullable":true,"type":"string"},{"metadata":{},"name":"CreationDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"UserId","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null},{"name":"posts_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Id","nullable":true,"type":"integer"},{"metadata":{},"name":"ParentId","nullable":true,"type":"integer"},{"metadata":{},"name":"PostTypeId","nullable":true,"type":"integer"},{"metadata":{},"name":"CreationDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Score","nullable":true,"type":"integer"},{"metadata":{},"name":"ViewCount","nullable":true,"type":"integer"},{"metadata":{},"name":"Body","nullable":true,"type":"string"},{"metadata":{},"name":"OwnerUserId","nullable":true,"type":"integer"},{"metadata":{},"name":"LastActivityDate","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Title","nullable":true,"type":"string"},{"metadata":{},"name":"Tags","nullable":true,"type":"string"},{"metadata":{},"name":"AnswerCount","nullable":true,"type":"integer"},{"metadata":{},"name":"CommentCount","nullable":true,"type":"integer"},{"metadata":{},"name":"FavoriteCount","nullable":true,"type":"integer"},{"metadata":{},"name":"ClosedDate","nullable":true,"type":"timestamp"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">&lt;ipython_unittest.magics.Status at 0x7f94dc760650&gt;\n&lt;ipython_unittest.magics.Status at 0x7f94d89b9250&gt;\n.....\n----------------------------------------------------------------------\nRan 5 tests in 8.422s\n\nOK\nOut[9]: &lt;unittest.runner.TextTestResult run=5 errors=0 failures=0&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;ipython_unittest.magics.Status at 0x7f94dc760650&gt;\n&lt;ipython_unittest.magics.Status at 0x7f94d89b9250&gt;\n.....\n----------------------------------------------------------------------\nRan 5 tests in 8.422s\n\nOK\nOut[9]: &lt;unittest.runner.TextTestResult run=5 errors=0 failures=0&gt;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Subtask 4: answering to questions about Spark related concepts\n\nPlease answer the following questions. Write your answer in one to two short paragraphs. Don't copy-paste; instead, write your own understanding.\n\n1. What is the difference between 'DataFrame', 'Dataset', and 'Resilient Distributed Datasets (RDD)'? \n2. When do you suggest using RDDs instead of using DataFrames?\n3. What is the main benefit of using DataSets instead of DataFrames?\n\nWrite your answers in the next cell."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fe8a2e0c-7e72-410b-b385-00503c0bc136","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["###### DataFrame vs. Dataset vs. RDD: \nDataFrame, Dataset, and RDD are all abstractions in Apache Spark, but they have different characteristics. A DataFrame is a distributed collection of data organized into named columns, similar to a table in a relational database. It has a schema, which defines the data types of each column, and can be thought of as a Dataset[Row]. A Dataset is a strongly typed distributed collection of objects, similar to a Java or Scala collection, and can be thought of as a DataFrame with type safety. An RDD is the basic abstraction in Spark, representing an immutable distributed collection of objects that can be processed in parallel. RDDs are more low-level than DataFrames and Datasets and provide more control over the processing logic but require more code to implement.\n\n###### When to use RDDs: \nRDDs are useful when dealing with unstructured or semi-structured data or when you need fine-grained control over the processing logic. For example, if you are processing text files or binary data, or if you need to perform complex operations that are not supported by DataFrames or Datasets, then RDDs may be the best choice. Additionally, if you need to interact with third-party libraries that are not compatible with DataFrames or Datasets, RDDs may also be a better option.\n \n###### Benefits of using DataSets over DataFrames: \nThe main benefit of using a DataSet over a DataFrame is type safety. Since a DataSet is a strongly typed collection, the compiler can catch type errors at compile-time instead of runtime, which can significantly reduce errors and debugging time. Additionally, DataSets support functional programming constructs such as map(), flatMap(), and filter() which can provide a more expressive and concise way of processing data. However, DataSets have a more limited set of available operations than DataFrames, and performance may not be as optimized as with DataFrames."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9c33ca21-1672-4c0c-a876-f73cbb8f65b2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ce10bf3c-1047-4231-96a5-4da1d3ec8fdb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Task2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1112977678366556}},"nbformat":4,"nbformat_minor":0}
